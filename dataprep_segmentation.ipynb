{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, cropsize, shift):\n",
    "        (cropx, cropy, cropz) = cropsize\n",
    "        (shiftx, shifty, shiftz) = shift\n",
    "        y,x,z = img.shape\n",
    "        startx = x//2-(cropx//2)\n",
    "        starty = y//2-(cropy//2)\n",
    "        startz = z//2-(cropz//2)      \n",
    "        return img[starty+shifty:starty+cropy+shifty,startx+shiftx:startx+cropx+shiftx, startz+shiftz:startz+cropz+shiftz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import util\n",
    "\n",
    "def make_blocks_vectorized(x,d):\n",
    "    \n",
    "    # d: chuck size\n",
    "    p,m,n = x.shape\n",
    "    return x.reshape(-1,m//d,d,n//d,d).transpose(1,3,0,2,4).reshape(-1,p,d,d) # shape: number of chuncks, x_dimention, d, d\n",
    "\n",
    "def unmake_blocks_vectorized(x,d,m,n):    \n",
    "    return np.concatenate(x).reshape(m//d,n//d,d,d).transpose(0,2,1,3).reshape(m,n)\n",
    "\n",
    "def path_prep_data(rootpath, patient_ID):\n",
    "    patient_ID = str(patient_ID)\n",
    "\n",
    "    idx_path = os.path.join(rootpath ,\"p\" + patient_ID + \"t1\", \"p\" + patient_ID + \"t1ct1_raw\")\n",
    "    roi_path = os.path.join(rootpath ,\"p\" + patient_ID + \"t1\", \"p\" + patient_ID + \"t1ct1_raw_roi\")\n",
    "\n",
    "    return  idx_path, roi_path\n",
    "\n",
    "\n",
    "idx_data = []\n",
    "roi_data = []\n",
    "\n",
    "\n",
    "patient_ID_list = [1,2,3,4]\n",
    "\n",
    "rootpath = os.path.join(os.path.dirname(os.getcwd()),'python')\n",
    "for patient_ID in  patient_ID_list:\n",
    "    idx_path, roi_path = path_prep_data(rootpath, patient_ID)\n",
    "\n",
    "    idx = np.load(idx_path + '.npy')\n",
    "    roi = np.load(roi_path + '.npy').transpose(3,0,1,2)\n",
    "\n",
    "    idx = (idx > 200)\n",
    "    idx = idx.astype(int)\n",
    "\n",
    "    # roi_new = np.zeros([roi.shape[0],200,128,256])\n",
    "    roi_new = np.zeros([roi.shape[0],200,128,256])\n",
    "    idx = crop_center(idx, (128, 200, 256),(0, 0, -30))\n",
    "    for i in range(roi.shape[0]):\n",
    "        roi_new[i] = crop_center(roi[i], (128, 200, 256),(0, 0, -30))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    d=128\n",
    "    roi_chuncks = []\n",
    "    idx_chuncks = make_blocks_vectorized(idx,d)\n",
    "    for i  in range(roi_new.shape[0]):\n",
    "        roi_chuncks.append(make_blocks_vectorized(roi_new[i],d))\n",
    "\n",
    "    roi_chuncks = np.array(roi_chuncks)\n",
    "\n",
    "    idx_data.append(idx_chuncks)\n",
    "    roi_data.append(roi_chuncks.transpose(1,0,2,3,4))\n",
    "\n",
    "    # use the whole volume to train instead of chunks\n",
    "    # idx_data.append(idx)\n",
    "    # roi_data.append(roi_new)\n",
    "\n",
    "\n",
    "\n",
    "idx_data = np.concatenate(idx_data, 0)\n",
    "roi_data = np.concatenate(roi_data, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_data = torch.Tensor(np.stack([idx_data], 4)).permute(0,4,1,2,3)\n",
    "#x_data = x_data.unsqueeze(2)\n",
    "y_data = torch.Tensor(np.array(roi_data))\n",
    "# y_data = y_data.unsqueeze(1)\n",
    "\n",
    "final_dataset = TensorDataset(x_data,y_data) # create your datset\n",
    "savepath = r\"G:\\My Drive\\PETCT\\python\"\n",
    "torch.save(final_dataset, os.path.join(savepath, 'data_roi', 'petctdataset_train_chunck.pth'))\n",
    "\n",
    "\n",
    "\n",
    "idx_data = []\n",
    "roi_data = []\n",
    "\n",
    "\n",
    "idx_data_whole = []\n",
    "roi_data_whole = []\n",
    "\n",
    "patient_ID_list = [7,8]\n",
    "\n",
    "rootpath = os.path.join(os.path.dirname(os.getcwd()),'python')\n",
    "for patient_ID in  patient_ID_list:\n",
    "    idx_path, roi_path = path_prep_data(rootpath, patient_ID)\n",
    "\n",
    "    idx = np.load(idx_path + '.npy')\n",
    "    roi = np.load(roi_path + '.npy').transpose(3,0,1,2)\n",
    "\n",
    "    idx = (idx > 200)\n",
    "    idx = idx.astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "    roi_new = np.zeros([roi.shape[0],200,128,256])\n",
    "    idx = crop_center(idx, (128, 200, 256),(0, 0, -30))\n",
    "    # roi_new = roi\n",
    "    for i in range(roi.shape[0]):\n",
    "        roi_new[i] = crop_center(roi[i], (128, 200, 256),(0, 0, -30))\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    idx_data_whole.append(idx)\n",
    "    roi_data_whole.append(roi_new)\n",
    "\n",
    "    \n",
    "x_data_whole = torch.Tensor(np.stack([np.array(idx_data_whole)], 4)).permute(0,4,1,2,3)\n",
    "\n",
    "y_data_whole = torch.Tensor(np.array(roi_data_whole))\n",
    "# y_data_whole = y_data_whole.unsqueeze(1)\n",
    "final_dataset_whole = TensorDataset(x_data_whole,y_data_whole) # create your datset\n",
    "torch.save(final_dataset_whole, os.path.join(savepath, 'data_roi', 'petctdataset_test_whole.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a872ac70b6e90aa5c902f72112b61e1b37ed5f2cfbca25f359328a225abc7c82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
